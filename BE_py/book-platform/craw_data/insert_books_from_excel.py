import os
import re
from pathlib import Path
from typing import Dict, Any, List, Optional

import mysql.connector
from mysql.connector import Error
import pandas as pd

from dotenv import load_dotenv
import math
import pandas as pd  # b·∫°n ƒë√£ import r·ªìi, gi·ªØ nguy√™n

import random


def generate_book_price(main_cat: str | None) -> float:
    """
    Sinh gi√° s√°ch (VNƒê) theo category ch√≠nh.
    Gi√° tr·∫£ v·ªÅ l√† s·ªë float, nh∆∞ng lu√¥n l√† b·ªôi s·ªë c·ªßa 1.000.
    """
    if not main_cat:
        main_cat = ""
    cat = main_cat.lower()

    # Thi·∫øu nhi / truy·ªán tranh
    if "thi·∫øu nhi" in cat or "truy·ªán tranh" in cat or "manga" in cat or "comic" in cat:
        price = random.randint(30, 80) * 1000        # 30k - 80k

    # Kinh t·∫ø, t√†i ch√≠nh, marketing, qu·∫£n tr·ªã
    elif "kinh t·∫ø" in cat or "t√†i ch√≠nh" in cat or "marketing" in cat \
         or "qu·∫£n tr·ªã" in cat or "kh·ªüi nghi·ªáp" in cat:
        price = random.randint(80, 200) * 1000       # 80k - 200k

    # K·ªπ nƒÉng s·ªëng, ph√°t tri·ªÉn b·∫£n th√¢n, t√¢m l√Ω
    elif "k·ªπ nƒÉng" in cat or "kƒ© nƒÉng" in cat or "ph√°t tri·ªÉn b·∫£n th√¢n" in cat \
         or "t√¢m l√Ω" in cat or "t√¢m lyÃÅ" in cat:
        price = random.randint(70, 180) * 1000       # 70k - 180k

    # C√¥ng ngh·ªá th√¥ng tin, l·∫≠p tr√¨nh, khoa h·ªçc
    elif "c√¥ng ngh·ªá" in cat or "l·∫≠p tr√¨nh" in cat or "khoa h·ªçc" in cat \
         or "cntt" in cat:
        price = random.randint(100, 250) * 1000      # 100k - 250k

    # VƒÉn h·ªçc, ti·ªÉu thuy·∫øt, truy·ªán ng·∫Øn
    elif "vƒÉn h·ªçc" in cat or "ti·ªÉu thuy·∫øt" in cat or "truy·ªán ng·∫Øn" in cat \
         or "ng√¥n t√¨nh" in cat or "th∆°" in cat:
        price = random.randint(60, 150) * 1000       # 60k - 150k

    # L·ªãch s·ª≠, vƒÉn h√≥a, t√¥n gi√°o
    elif "l·ªãch s·ª≠" in cat or "vƒÉn h√≥a" in cat or "t√¥n gi√°o" in cat:
        price = random.randint(80, 220) * 1000       # 80k - 220k

    # Gi√°o tr√¨nh, s√°ch gi√°o khoa, tham kh·∫£o
    elif "gi√°o khoa" in cat or "tham kh·∫£o" in cat or "gi√°o tr√¨nh" in cat:
        price = random.randint(70, 200) * 1000       # 70k - 200k

    # Fallback chung
    else:
        price = random.randint(50, 180) * 1000       # 50k - 180k

    return float(price)


def none_if_nan(value):
    """
    N·∫øu value l√† NaN / pandas.NA / None / chu·ªói r·ªóng -> tr·∫£ v·ªÅ None.
    Ng∆∞·ª£c l·∫°i tr·∫£ v·ªÅ ch√≠nh n√≥.
    """
    if value is None:
        return None
    try:
        if pd.isna(value):
            return None
    except Exception:
        pass
    # N·∫øu l√† chu·ªói 'nan', 'NaN', 'null', 'None'... th√¨ c≈©ng coi nh∆∞ None
    s = str(value).strip()
    if s.lower() in ("nan", "none", "null", "na", "n/a"):
        return None
    return value


# ================== C·∫§U H√åNH C∆† B·∫¢N ==================

BASE_DIR = Path(__file__).resolve().parent
EXCEL_FILE = BASE_DIR / "merged_books_with_manual_category.xlsx"

# ƒê·ªçc .env n·∫øu c√≥
load_dotenv()

DB_CONFIG = {
    "host": os.getenv("MYSQL_HOST", "localhost"),
    "user": os.getenv("MYSQL_USER", "root"),
    "password": os.getenv("MYSQL_PASSWORD", ""),
    "database": os.getenv("MYSQL_DB", "bookstore"),
    "port": int(os.getenv("MYSQL_PORT", "3306")),
}


# ================== H√ÄM TI·ªÜN √çCH ==================

def get_connection():
    try:
        conn = mysql.connector.connect(**DB_CONFIG)
        if conn.is_connected():
            print("‚úÖ K·∫øt n·ªëi MySQL th√†nh c√¥ng.")
            return conn
    except Error as e:
        print("‚ùå L·ªói k·∫øt n·ªëi MySQL:", e)
    return None


def parse_year(published_date: Any) -> Optional[int]:
    """
    L·∫•y nƒÉm (4 ch·ªØ s·ªë ƒë·∫ßu ti√™n) t·ª´ tr∆∞·ªùng published_date (vd: '2017-05-01', '2019', '2018-?').
    Kh√¥ng parse ƒë∆∞·ª£c -> None.
    """
    if published_date is None:
        return None
    s = str(published_date).strip()
    if not s:
        return None
    m = re.search(r"(\d{4})", s)
    if not m:
        return None
    try:
        year = int(m.group(1))
        if 1000 <= year <= 2100:
            return year
    except ValueError:
        return None
    return None


def normalize_isbn_value(raw: Any) -> str:
    """
    Chu·∫©n h√≥a 1 gi√° tr·ªã ISBN t·ª´ Excel:
    - NaN, None, 'nan', 'NaN', 'null', 'None', 'N/A' -> ''
    - C·∫Øt v·ªÅ t·ªëi ƒëa 13 k√Ω t·ª±
    """
    s = str(raw).strip()
    if not s:
        return ""
    s_lower = s.lower()
    if s_lower in ("nan", "none", "null", "na", "n/a"):
        return ""
    # C·∫Øt v·ªÅ t·ªëi ƒëa 13 k√Ω t·ª±
    return s[:13]


def choose_isbn(row: pd.Series) -> Optional[str]:
    """
    Ch·ªçn isbn ƒë·ªÉ insert:
    - ∆∞u ti√™n isbn_13
    - n·∫øu kh√¥ng c√≥ -> d√πng isbn_10
    - n·∫øu ƒë·ªÅu tr·ªëng -> None
    """
    isbn_13 = normalize_isbn_value(row.get("isbn_13", ""))
    isbn_10 = normalize_isbn_value(row.get("isbn_10", ""))

    if isbn_13:
        return isbn_13
    if isbn_10:
        return isbn_10
    return None


# ================== C√ÅC B∆Ø·ªöC INSERT ==================

def clear_old_data(conn):
    """
    X√≥a d·ªØ li·ªáu c≈© trong c√°c b·∫£ng li√™n quan tr∆∞·ªõc khi insert.
    Gi·ªØ nguy√™n c·∫•u tr√∫c b·∫£ng.
    Th·ª© t·ª± x√≥a ph·∫£i t√¥n tr·ªçng foreign key.
    """
    cursor = conn.cursor()
    print("üîÑ ƒêang x√≥a d·ªØ li·ªáu c≈©...")

    # T·∫°m t·∫Øt FK ƒë·ªÉ truncate cho d·ªÖ
    cursor.execute("SET FOREIGN_KEY_CHECKS = 0")

    tables = [
        "book_images",
        "book_categories",
        "books",
        "categories",
        "authors",
        "publishers",
        # C√°c b·∫£ng kh√°c n·∫øu b·∫°n mu·ªën x√≥a s·∫°ch lu√¥n (t√πy):
        # "ratings", "user_actions", "recommendations", ...
    ]

    for tbl in tables:
        print(f"  TRUNCATE TABLE {tbl}...")
        cursor.execute(f"TRUNCATE TABLE {tbl}")

    cursor.execute("SET FOREIGN_KEY_CHECKS = 1")
    conn.commit()
    cursor.close()
    print("‚úÖ ƒê√£ x√≥a d·ªØ li·ªáu c≈© trong c√°c b·∫£ng li√™n quan.")


def load_excel() -> pd.DataFrame:
    if not EXCEL_FILE.exists():
        raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file: {EXCEL_FILE}")
    print(f"üìñ ƒêang ƒë·ªçc file Excel: {EXCEL_FILE}")
    df = pd.read_excel(EXCEL_FILE)

    # Chu·∫©n h√≥a c√°c c·ªôt ch√≠nh
    for col in ["title", "author_name", "publisher", "language", "cover_url"]:
        if col not in df.columns:
            df[col] = ""
        df[col] = df[col].fillna("").astype(str).str.strip()

    # C·ªôt category ch√≠nh t·ª´ manual
    if "main_category_from_manual" not in df.columns:
        raise ValueError(
            "File Excel kh√¥ng c√≥ c·ªôt 'main_category_from_manual'. "
            "H√£y ki·ªÉm tra l·∫°i b∆∞·ªõc rebuild_categories_from_title."
        )

    df["main_category_from_manual"] = (
        df["main_category_from_manual"].fillna("").astype(str).str.strip()
    )

    # Lo·∫°i b·ªè c√°c d√≤ng kh√¥ng c√≥ title ho·∫∑c kh√¥ng c√≥ category
    before = len(df)
    df = df[(df["title"] != "") & (df["main_category_from_manual"] != "")]
    after = len(df)
    print(
        f"üì¶ S·ªë s√°ch d√πng ƒë∆∞·ª£c sau khi l·ªçc title & category: {after} (b·ªè {before - after})")

    return df


def insert_authors(conn, df: pd.DataFrame) -> Dict[str, int]:
    """
    Insert unique authors v√†o b·∫£ng authors.
    Tr·∫£ v·ªÅ mapping author_name -> author_id.
    """
    cursor = conn.cursor()
    author_names = sorted(set(df["author_name"].tolist()))
    author_names = [a for a in author_names if a]  # b·ªè r·ªóng

    print(f"üßë‚Äçüíª S·ªë t√°c gi·∫£ unique: {len(author_names)}")

    sql = "INSERT IGNORE INTO authors (author_name, bio, status) VALUES (%s, %s, %s)"
    data = [(name, None, "active") for name in author_names]
    if data:
        cursor.executemany(sql, data)
        conn.commit()
        print(f"‚úÖ ƒê√£ insert {cursor.rowcount} t√°c gi·∫£.")

    # L·∫•y mapping l·∫°i
    cursor.execute("SELECT author_id, author_name FROM authors")
    rows = cursor.fetchall()
    author_map = {name: aid for (aid, name) in rows}
    cursor.close()
    return author_map


def insert_publishers(conn, df: pd.DataFrame) -> Dict[str, int]:
    """
    Insert unique publishers v√†o b·∫£ng publishers.
    Tr·∫£ v·ªÅ mapping publisher_name -> publisher_id.
    """
    cursor = conn.cursor()
    publisher_names = sorted(set(df["publisher"].tolist()))
    publisher_names = [p for p in publisher_names if p]

    print(f"üè¢ S·ªë NXB unique: {len(publisher_names)}")

    sql = "INSERT IGNORE INTO publishers (publisher_name, status) VALUES (%s, %s)"

    data = [(name, "active") for name in publisher_names]
    if data:
        cursor.executemany(sql, data)
        conn.commit()
        print(f"‚úÖ ƒê√£ insert {cursor.rowcount} NXB.")

    cursor.execute("SELECT publisher_id, publisher_name FROM publishers")
    rows = cursor.fetchall()
    publisher_map = {name: pid for (pid, name) in rows}
    cursor.close()
    return publisher_map


def insert_categories(conn, df: pd.DataFrame) -> Dict[str, int]:
    """
    Insert unique categories (t·ª´ main_category_from_manual) v√†o b·∫£ng categories.
    Tr·∫£ v·ªÅ mapping category_name -> category_id.
    """
    cursor = conn.cursor()
    cat_names = sorted(set(df["main_category_from_manual"].tolist()))
    cat_names = [c for c in cat_names if c]

    print(f"üè∑Ô∏è  S·ªë category unique: {len(cat_names)}")

    sql = "INSERT IGNORE INTO categories (category_name, status) VALUES (%s, %s)"

    data = [(name, "active") for name in cat_names]
    if data:
        cursor.executemany(sql, data)
        conn.commit()
        print(f"‚úÖ ƒê√£ insert {cursor.rowcount} category.")

    cursor.execute("SELECT category_id, category_name FROM categories")
    rows = cursor.fetchall()
    category_map = {name: cid for (cid, name) in rows}
    cursor.close()
    return category_map


def insert_books_and_children(
    conn,
    df: pd.DataFrame,
    author_map: Dict[str, int],
    publisher_map: Dict[str, int],
    category_map: Dict[str, int],
):
    """
    Insert books, book_categories, book_images.
    ƒê·∫£m b·∫£o m·ªói d√≤ng s√°ch trong df t·∫°o ra:
      - 1 row trong books
      - 1 row trong book_categories
      - 1 row trong book_images
    => T·ªïng s·ªë d√≤ng 3 b·∫£ng n√†y nh∆∞ nhau.
    """
    cursor = conn.cursor()

    book_sql = """
        INSERT INTO books
        (title, author_id, publisher_id, price, stock_quantity,
         description, publication_year, isbn, avg_rating, rating_count,
         language, format, status)
        VALUES
        (%s, %s, %s, %s, %s,
         %s, %s, %s, %s, %s,
         %s, %s, %s)
    """

    book_category_sql = """
        INSERT INTO book_categories (book_id, category_id)
        VALUES (%s, %s)
    """

    book_image_sql = """
        INSERT INTO book_images (book_id, image_url, is_main)
        VALUES (%s, %s, %s)
    """

    book_count = 0
    used_isbn = set()  # th√™m d√≤ng n√†y tr∆∞·ªõc v√≤ng for

    for idx, row in df.iterrows():
        title = str(row.get("title", "")).strip()
        if not title:
            continue

        author_name = str(row.get("author_name", "")).strip()
        publisher_name = str(row.get("publisher", "")).strip()

        # description c√≥ th·ªÉ l√† NaN -> convert
        description_raw = row.get("description", None)
        description = none_if_nan(description_raw)

        # published_date c√≥ th·ªÉ NaN -> convert tr∆∞·ªõc khi parse_year
        published_date_raw = none_if_nan(row.get("published_date", None))
        pub_year = parse_year(published_date_raw)

        language_raw = row.get("language", "")
        language = none_if_nan(language_raw)
        if language is not None:
            language = str(language).strip() or None

        isbn = choose_isbn(row)

        # Tr√°nh tr√πng ISBN trong c√πng batch
        if isbn:
            if isbn in used_isbn:
                # N·∫øu ISBN ƒë√£ d√πng r·ªìi, b·ªè ISBN cho b·∫£n ghi n√†y (insert NULL)
                # print(f"‚ö†Ô∏è ISBN tr√πng trong batch, b·ªè ISBN cho s√°ch: {title} ({isbn})")
                isbn = None
            else:
                used_isbn.add(isbn)

        # Gi√° & t·ªìn kho: b·∫°n t√πy ch·ªânh
        main_cat = row.get("main_category_from_manual")
        price = generate_book_price(main_cat)
        stock_quantity = random.randint(100, 1000)

        avg_rating = 0.0
        rating_count = 0

        book_format = "paperback"
        status = "active"

        author_id = author_map.get(author_name)
        publisher_id = publisher_map.get(publisher_name)

        book_values = (
            title,
            author_id,
            publisher_id,
            price,
            stock_quantity,
            description,   # ƒë√£ none_if_nan
            pub_year,      # int ho·∫∑c None
            isbn,          # string ho·∫∑c None
            avg_rating,
            rating_count,
            language,      # string ho·∫∑c None
            book_format,
            status,
        )
        cursor.execute(book_sql, book_values)

        book_id = cursor.lastrowid

        # book_categories
        cat_name = str(row.get("main_category_from_manual", "")).strip()
        category_id = category_map.get(cat_name)
        if category_id:
            cursor.execute(book_category_sql, (book_id, category_id))
        else:
            print(
                f"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y category_id cho '{cat_name}' (book: {title})")

        # book_images
        cover_url_raw = row.get("cover_url", "")
        cover_url = none_if_nan(cover_url_raw)
        if cover_url:
            cover_url = str(cover_url).strip()
            cursor.execute(book_image_sql, (book_id, cover_url, 1))
        else:
            print(f"‚ö†Ô∏è  S√°ch '{title}' kh√¥ng c√≥ cover_url.")

    conn.commit()
    cursor.close()
    print(f"‚úÖ ƒê√£ insert {book_count} s√°ch + categories + images.")


def main():
    conn = get_connection()
    if not conn:
        return

    try:
        # 1) X√≥a d·ªØ li·ªáu c≈©
        clear_old_data(conn)

        # 2) ƒê·ªçc file Excel
        df = load_excel()

        # 3) Insert authors, publishers, categories
        author_map = insert_authors(conn, df)
        publisher_map = insert_publishers(conn, df)
        category_map = insert_categories(conn, df)

        # 4) Insert books + book_categories + book_images
        insert_books_and_children(
            conn, df, author_map, publisher_map, category_map)

        print("üéâ Ho√†n t·∫•t import d·ªØ li·ªáu s√°ch v√†o database 'bookstore'.")

    finally:
        conn.close()
        print("üîå ƒê√£ ƒë√≥ng k·∫øt n·ªëi MySQL.")


if __name__ == "__main__":
    main()
